{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1642020582706,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "TOE8Uq366Zb3",
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix,accuracy_score,r2_score, matthews_corrcoef, make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def result_model(model,X,Y, f1 = True, f1_aff = True, mat = True) :\n",
    "    Y_model =model.predict(X)\n",
    "\n",
    "    if f1:\n",
    "        f1_scor = f1_score(Y,Y_model)\n",
    "        if f1_aff:\n",
    "            print('Le f1 score vaut',f1_scor)\n",
    "        return(f1_scor)\n",
    "        \n",
    "        \n",
    "    # Matrice de confusion\n",
    "    if mat:\n",
    "        cm_model = confusion_matrix(Y, Y_model)\n",
    "        plt.rcParams['figure.figsize'] = (5, 5)\n",
    "        sns.heatmap(cm_model, annot = True)\n",
    "        plt.title(str(model))\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCqXSO0k5qBK"
   },
   "source": [
    "# Neuronal Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2279,
     "status": "ok",
     "timestamp": 1642020588849,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "-2TMs1705YQH"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"https://www.data.mclavier.com/prj_datascience/train_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqzFKktu59zc"
   },
   "source": [
    "## Pre-processing\n",
    "\n",
    "On sépare la variable à expliquer des variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1642020590439,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "XKRAQm1O6BcY"
   },
   "outputs": [],
   "source": [
    "X = train.drop(columns = 'Response')\n",
    "Y = train['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WW4T6qyR6FR4"
   },
   "source": [
    "On sépare les données en train et test puis on les scale avec les méthodes de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1642020591448,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "xOeBTg0F6KHr",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,train_size = 0.85)\n",
    "\n",
    "scaler=StandardScaler() \n",
    "\n",
    "X_scal_train = scaler.fit_transform(X_train)\n",
    "X_scal_test = scaler.transform(X_test) \n",
    "\n",
    "X_scal_train = pd.DataFrame(X_scal_train,index= X_train.index)\n",
    "X_scal_test = pd.DataFrame(X_scal_test,index= X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD_SCdwA6Oz-"
   },
   "source": [
    "## Implémentation\n",
    "\n",
    "On applique ensuite directement notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "executionInfo": {
     "elapsed": 38386,
     "status": "ok",
     "timestamp": 1642020632707,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "eSqKaSiI6Vlk",
    "outputId": "32ea0e78-4e88-4d10-f6d9-342f0cfb574a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le f1 score vaut 0.41579419682919533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41579419682919533"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=0).fit(X_scal_train, Y_train)\n",
    "result_model(clf, X_scal_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rV6vka8w-o16"
   },
   "source": [
    "## Perception simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMTjAmEOg48I"
   },
   "source": [
    "On sépare les données en train et test puis on les scale avec les méthodes de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1642020644986,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "msD7Xaz7g1Of"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X, Y,train_size = 0.85)\n",
    "\n",
    "scaler=StandardScaler() \n",
    "\n",
    "X2_scal_train = scaler.fit_transform(X2_train)\n",
    "X2_scal_test = scaler.transform(X2_test) \n",
    "\n",
    "X2_scal_train = pd.DataFrame(X2_scal_train,index= X2_train.index)\n",
    "X2_scal_test = pd.DataFrame(X2_scal_test,index= X2_test.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KD--IKub9K9q"
   },
   "source": [
    "Nous importons les classes Sequential et Dense pour définir notre modèle et son architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1642020648429,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "8xaq4fAn9MJi"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3uTl5LD9Rtl"
   },
   "source": [
    "La classe Sequential est une structure, initialement vide, qui permet de définir un empilement de couches de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1642020650254,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "jPaX7kzW9Upz"
   },
   "outputs": [],
   "source": [
    "modelSimple = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CE3ZUYd9e1I"
   },
   "source": [
    "Nous ajoutons une couche qui relie directement : \n",
    " \n",
    "\n",
    "1.  la couche d'entrée, input_dim: nombre de neurones qui correspond au nombre de variables prédictives ;\n",
    "2.   la couche de sortie, units=1:une seule sortie puisque la variables cible est binaire, codée 1/0 ;\n",
    "3.    une fonction d'activation sigmoïde.\n",
    "\n",
    "La fonction Dense permet de connecter tous les neurones de la couche précédente à tous les neurones de la couche suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1642020658749,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "rC1128XL9ibp"
   },
   "outputs": [],
   "source": [
    "modelSimple.add(Dense(units=1,input_dim=3,activation=\"sigmoid\",input_shape=(None,15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1642020660236,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "CJrku220ZKIj",
    "outputId": "051057c8-b8c3-4500-b49c-5b92aeeda655",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, None, 1)           16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(modelSimple.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSq1vWHR9_5G"
   },
   "source": [
    "En entrée du neurone de la couche de sortie, nous avons la combinaison linéaire suivante : \n",
    "$$d(X)=a_0+a_1X_1+a_2X_2$$\n",
    "Après application de la fonction d'activation sigmöïde.\n",
    "\n",
    "Nous avons en sortie du neurone de la couche de sortie :\n",
    "\n",
    "$$\n",
    "g(d)=\\frac{1}{1+e^{-d}}\n",
    "$$\n",
    "\n",
    "$g(d)$ est une estimation de la probabilité conditionnelle $P(Y=pos|X_1,X_2)$ qui est déterminante dans les problèmatiques de classement.\n",
    "\n",
    "L'étape suivante consiste à spécifier les caractéristiques de l'algorithme d'apprentissage : la fonction de perte à optimiser est l'entropie croisée binaire, elle correspond à la log-vraisemblance d'un échantillon où la probabilité conditionnelle d'appartenance aux classes est modélisée à l'aide de la loi binomiale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHTVP6cg-j6w"
   },
   "source": [
    "Le modèle est ajusté en utilisant la fonction binaire de perte d'entropie croisée et à travers l'utilisation de la version efficace d' Adam  (algorithme d'optimisation) de la descente de gradient stochastique.\n",
    "La métrique utilisée pour mesurer la qualité de la modélisation est le taux de reconnaissance ou taux de succès."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1642020666450,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "u1H7QZ9PQVr_"
   },
   "outputs": [],
   "source": [
    "modelSimple.compile(loss = \"binary_crossentropy\",optimizer = \"Adamax\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yjb_V3Id_fvS"
   },
   "source": [
    "Le modèle à 150 époques d'apprentissage est adapté à la taille de lot par défaut de 200 échantillons. L'évaluation des performances du modèle est effectué à la fin de chaque époque d'apprentissage sur l'ensemble des données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72379,
     "status": "ok",
     "timestamp": 1642020743318,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "nuuyPJ_3TsvB",
    "outputId": "7b6bec68-b266-4bbe-c8a2-4ed810239570",
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 15) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 15), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 15).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 15) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 15), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 15).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ed58e80880>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 200    \n",
    "nb_epoch = 150\n",
    "modelSimple.fit(X2_scal_train, Y2_train,epochs=nb_epoch,batch_size=batch_size, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1642020755175,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "IIlfYz1GN2qL",
    "outputId": "30d9513a-d64e-45e7-c077-9528169b8544",
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 15) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 15), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 15).\n"
     ]
    }
   ],
   "source": [
    "Y2_model = modelSimple.predict(X2_scal_test)\n",
    "Y2_model =Y2_model.reshape(-1)\n",
    "Y2_model_classes = (Y2_model > 0.5).astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a6eVIAAAcVJ"
   },
   "source": [
    "Métriques de précision de la classification et de la perte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1003,
     "status": "ok",
     "timestamp": 1642020761511,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "oqYBJrQjnYIN",
    "outputId": "d76d611d-918f-4b8c-f68a-052d7e9b4628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 15) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 15), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 15).\n",
      "306/306 [==============================] - 1s 1ms/step - loss: 0.3576 - accuracy: 0.7966\n",
      "perte: 0.357551246881485, accuracy: 0.7966414093971252\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = modelSimple.evaluate(X2_scal_test, Y2_test)\n",
    "print(\"perte: {}, accuracy: {}\".format(test_loss, test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEwHR59cHWSo"
   },
   "source": [
    "Evaluation du F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1642021522264,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "XZCkXqjDWnh-",
    "outputId": "a587322b-a0c0-4a2d-ff70-b8103f86c16e",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le f1 score vaut 0.208133971291866\n"
     ]
    }
   ],
   "source": [
    "f1_scor2 = f1_score(Y2_test,Y2_model_classes)\n",
    "print('Le f1 score vaut',f1_scor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpeknZcxBCZf"
   },
   "source": [
    "## Perception multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt2fy9AyBdXc"
   },
   "source": [
    "Nous passons maintenant à un perceptron multicouche. Nous créons toujours structure Sequential, dans lequel nous ajoutons successivement deux objets Dense; le premier faisant la jonction entre la couche d'entrée et la couche cachée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0zQZuQqBLiB"
   },
   "source": [
    "On sépare les données en train et test puis on les scale avec les méthodes de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1642020770444,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "LhbP8Y9VBLOk",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "X3_train, X3_test, Y3_train, Y3_test = train_test_split(X, Y,train_size = 0.85)\n",
    "\n",
    "scaler=StandardScaler() \n",
    "\n",
    "X3_scal_train = scaler.fit_transform(X3_train)\n",
    "X3_scal_test = scaler.transform(X3_test) \n",
    "\n",
    "X3_scal_train = pd.DataFrame(X3_scal_train,index= X3_train.index)\n",
    "X3_scal_test = pd.DataFrame(X3_scal_test,index= X3_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiation du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1642020976857,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "LE2vvevLBmUg"
   },
   "outputs": [],
   "source": [
    "modelMc = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXomuHIYI-lP"
   },
   "source": [
    "Nous ajoutons trois couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1642020977986,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "whPqzucNBogN"
   },
   "outputs": [],
   "source": [
    "modelMc.add(Dense(units=6,input_dim=3,activation=\"sigmoid\",input_shape=(None,15)))\n",
    "modelMc.add(Dense(units=3,input_dim=3, activation=\"sigmoid\",input_shape=(None,15)))\n",
    "modelMc.add(Dense(units=1,input_dim=3,activation=\"sigmoid\",input_shape=(None,15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1642020979097,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "URFsTR42ChGk",
    "outputId": "112c4fe0-f9f2-4210-9c87-3faf4140d867",
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, None, 6)           96        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 3)           21        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, None, 1)           4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(modelMc.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1642021006865,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "dLvPA0RCBp0i"
   },
   "outputs": [],
   "source": [
    "modelMc.compile(loss = \"binary_crossentropy\",optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URfYlS5_HKxc"
   },
   "source": [
    "Le modèle à 150 époques d'apprentissage est adapté à la taille de lot par défaut de 200 échantillons. L'évaluation des performances du modèle est effectué à la fin de chaque époque d'apprentissage sur l'ensemble de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82206,
     "status": "ok",
     "timestamp": 1642021090297,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "puVdh_EsBrm8",
    "outputId": "118ee378-3168-4550-a484-8f972d45fc49",
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ed5a9f3250>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 200\n",
    "nb_epoch = 150\n",
    "modelSimple.fit(X3_scal_train, Y3_train,epochs=nb_epoch,batch_size=batch_size, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1642021093154,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "58XWg5yCCLcO"
   },
   "outputs": [],
   "source": [
    "Y3_model = modelSimple.predict(X3_scal_test)\n",
    "Y3_model =Y3_model.reshape(-1)\n",
    "Y3_model_classes = (Y3_model > 0.5).astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQDsJXdZFjob"
   },
   "source": [
    "Métriques de précision de la classification et de la perte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1642021097470,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "lAEXU0yMCO_k",
    "outputId": "82dbabdd-db38-407a-a8b1-fc8e979fe803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.7960\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = modelSimple.evaluate(X3_scal_test, Y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'perte: 0.3584350049495697, accuracy: 0.7960270047187805'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"perte: {}, accuracy: {}\".format(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvDaMLUnHhXX"
   },
   "source": [
    "Evaluation du F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1642021099599,
     "user": {
      "displayName": "Soraya Chebak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2fvKpDnna33wmxFYA5nm5yMmTR8UfkpMrcciHEw=s64",
      "userId": "03192094324194126743"
     },
     "user_tz": -60
    },
    "id": "vPGV7Rk6CWUK",
    "outputId": "7588ea05-ad11-4efe-a14c-ebefcdf1d17b",
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le f1 score vaut 0.2253737064009199\n"
     ]
    }
   ],
   "source": [
    "f1_scor3 = f1_score(Y3_test,Y3_model_classes)\n",
    "print('Le f1 score vaut',f1_scor3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "authorship_tag": "ABX9TyMsFpKg2sWbjJLzJrufCKhA",
   "collapsed_sections": [],
   "name": "RN2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
