
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>XGBoost &#8212; G1 - Apprentissage statistique</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Modèle finale" href="../5_retenu/50_mod_final.html" />
    <link rel="prev" title="Gradient Boosting" href="46_grad_boost.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">G1 - Apprentissage statistique</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../1_desc/10_description.html">
   Description des données
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2_prep/20_generale.html">
   Préparation des données
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3_mesure/30_mesure.html">
   Mesure
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="40_modeles.html">
   Implémentation des modèles
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="41_logistique.html">
     Logistique
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="42_svc.html">
     Support Vector Classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="43_cart.html">
     CART
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="44_rf.html">
     Random Forest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="45_rn.html">
     Réseau de neurones
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="46_grad_boost.html">
     Gradient Boosting
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     XGBoost
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5_retenu/50_mod_final.html">
   Modèle finale
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#telechargement-des-donnees">
   Téléchargement des données
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pre-processing">
   Pre-processing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implementation">
   Implémentation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tuning">
   Tuning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#etape-1-initialisation">
     Étape 1 : Initialisation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#etape-2-max-depth-et-min-child-weight">
     Étape 2 : max_depth et min_child_weight
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#etape-3-gamma">
     Étape 3 : Gamma
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#etape-4-subsample-et-colsample-bytree">
     Etape 4 : subsample et colsample_bytree
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#etape-5-reg-alpha">
     Étape 5 : reg_alpha
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#etape-6-learning-rate">
     Etape 6 : Learning rate
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-under-sampler">
   Random Under Sampler
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parametres-finaux">
   Paramètres finaux
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rappels-theoriques">
   Rappels théoriques
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="xgboost">
<h1>XGBoost<a class="headerlink" href="#xgboost" title="Permalink to this headline">¶</a></h1>
<div class="section" id="telechargement-des-donnees">
<h2>Téléchargement des données<a class="headerlink" href="#telechargement-des-donnees" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://www.data.mclavier.com/prj_datascience/train_v1.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="pre-processing">
<h2>Pre-processing<a class="headerlink" href="#pre-processing" title="Permalink to this headline">¶</a></h2>
<p>On sépare dans un premier temps les variables explicatives et la variable à expliquer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;Response&#39;</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;Response&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Ensuite, on décompose en bdd train et test puis on scale les données grâce à sklearn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span><span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.85</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Le modèle final sera entrainé sur l’intégralité de la base que nous possédons. Mais actuellement, nous souhaitons mesure le caractère prédictif de nos données et donc pour éviter l’overfitting, nous séparons tout de même nos données.</p>
</div>
<div class="section" id="implementation">
<h2>Implémentation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgb0</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">xgb0</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Le f1 score vaut 0.39774506733479487
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/47_xgboost_13_0.png" src="../../_images/47_xgboost_13_0.png" />
</div>
</div>
<p>Visualisation du graphique <strong>Features importance</strong>.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">xgb0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/47_xgboost_15_0.png" src="../../_images/47_xgboost_15_0.png" />
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Le graphe des features importance du modèle tuné se trouve à la fin de ce notebook.</p>
</div>
</div>
<div class="section" id="tuning">
<h2>Tuning<a class="headerlink" href="#tuning" title="Permalink to this headline">¶</a></h2>
<p>Pour tuner le programme, on s’inspire grandement de <a class="reference external" href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/#h2_9">ce site</a>.
Nous utilisons la fonction GridSearchCV de <em>sklearn</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>  
</pre></div>
</div>
</div>
</div>
<p>Si la metrics f1 existait dans la fonction cv d’XGBoost, nous aurions pu l’utiliser de la cross validation pour adapter <em>n_estimators</em> au fur et à mesure du tuning. Actuellement, ce n’est pas le cas, nous nous contenterons d’utiliser la même méthode d’entrainement et de test que précédemment. Ceci a pour intérêt de permettre facilement de comparer les résultats.</p>
<p>Voici l’algorithme pour l’exemple :</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">modelfit</span><span class="p">(</span><span class="n">alg</span><span class="p">,</span> <span class="n">dtrain</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">useTrainCV</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">cv_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">useTrainCV</span><span class="p">:</span>
        <span class="n">xgb_param</span> <span class="o">=</span> <span class="n">alg</span><span class="o">.</span><span class="n">get_xgb_params</span><span class="p">()</span>
        <span class="n">xgtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">dtrain</span><span class="p">[</span><span class="n">predictors</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">dtrain</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">cvresult</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">cv</span><span class="p">(</span><span class="n">xgb_param</span><span class="p">,</span> <span class="n">xgtrain</span><span class="p">,</span> <span class="n">num_boost_round</span><span class="o">=</span><span class="n">alg</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">],</span> <span class="n">nfold</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="s1">&#39;error&#39;</span><span class="p">,</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="n">early_stopping_rounds</span><span class="p">)</span>
        <span class="n">alg</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">cvresult</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1">#Fit the algorithm on the data</span>
    <span class="n">alg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dtrain</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span> <span class="n">dtrain</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
        
    <span class="c1">#Predict training set:</span>
    <span class="n">dtrain_predictions</span> <span class="o">=</span> <span class="n">alg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dtrain</span><span class="p">[</span><span class="n">predictors</span><span class="p">])</span>
    <span class="c1"># dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Estimateur efficient :&quot;</span><span class="p">,</span> <span class="n">cvresult</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Mesures :&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f1 : &quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">dtrain</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtrain_predictions</span><span class="p">))</span>

    <span class="k">return</span><span class="p">(</span><span class="n">alg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="etape-1-initialisation">
<h3>Étape 1 : Initialisation<a class="headerlink" href="#etape-1-initialisation" title="Permalink to this headline">¶</a></h3>
<p>Dans un premier temps, on récupère les paramètres de bases que l’on va tuner par la suite.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="n">xgb0</span><span class="o">.</span><span class="n">get_xgb_params</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>On modifie quelques paramètres de base au regard des TP réalisés.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;seed&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">27</span> <span class="c1"># Pour retrouver les résultats</span>
<span class="n">params</span><span class="p">[</span><span class="s1">&#39;nthread&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">7</span> <span class="c1"># Utilisation maximale des capacités de la machine utilisée</span>
<span class="n">params</span><span class="p">[</span><span class="s2">&quot;use_label_encoder&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># Masquer les warning.</span>
</pre></div>
</div>
</div>
</div>
<p>Le paramètre <em>n_estimators</em> est particulier, nous l’estimerons plusieurs fois à différentes étapes du tuning.</p>
<p>Nous définissons dans un premier temps les valeurs que l’on souhaite tester.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_estimator1</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;n_estimators&#39;</span><span class="p">:[</span><span class="mi">900</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1100</span><span class="p">,</span> <span class="mi">1200</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Nous utilisons l’outil gsearch de <em>sklearn</em> pour tester différents paramètres en ayant comme mesure de scoring le F1-Score. Voici l’implémentation qui sera masquée par la suite.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Response&#39;</span>
<span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">target</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gsearch_est1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
    <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_estimator1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
 
<span class="n">gsearch_est1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span><span class="n">train</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>On récupère les paramètres optimaux identifiés.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gsearch_est1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch_est1</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;n_estimators&#39;: 1000}, 0.40548819026663674)
</pre></div>
</div>
</div>
</div>
<p>Nous modifions le paramètres <em>n_estimators</em> suite au résultat ci-dessus.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Le F1-Score en sorti du grid_search ne peut pas être comparé complètement au f1 initiale car le grid_search utilise de la cross validation et donc pas le même jeu de données test.</p>
</div>
<p>Nous entrainons le modèle avec les nouveaux paramètres pour pouvoir comparer. Par la suite, cette étape ne sera pas tout le temps réalisée.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgb1</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
<span class="n">xgb1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Le f1 score vaut 0.41000852999715665
</pre></div>
</div>
</div>
</div>
<p>Le f1-score s’est amélioré de 0.02 point. Nous continuons le tuning.</p>
</div>
<div class="section" id="etape-2-max-depth-et-min-child-weight">
<h3>Étape 2 : max_depth et min_child_weight<a class="headerlink" href="#etape-2-max-depth-et-min-child-weight" title="Permalink to this headline">¶</a></h3>
<p>Lors du tuning, nous diminuons le nombre d’estimators pour réduire le temps de calcul</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">140</span>
</pre></div>
</div>
</div>
</div>
<p>On tune max_depth et min_child_weight</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_test1</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span>
 <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Nous utilisons l’outil gsearch de <em>sklearn</em> pour tester différents paramètres en ayant comme mesure de scoring le F1-Score. Voici l’implémentation qui sera masquée par la suite.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gsearch1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
    <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
 
<span class="n">gsearch1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span><span class="n">train</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>On récupère les paramètres optimaux identifiés.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gsearch1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;max_depth&#39;: 9, &#39;min_child_weight&#39;: 4}, 0.41359753361385065)
</pre></div>
</div>
</div>
</div>
<p>Nous pouvons modifier <em>min_child_weight</em> dans les paramètres.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;max_depth&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">params</span><span class="p">[</span><span class="s2">&quot;min_child_weight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>
</div>
</div>
</div>
<p>Étant à la limite sur les deux paramètres, nous testons avec des paramètres plus forts.</p>
<div class="cell tag_remove-output tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_test2</span> <span class="o">=</span> <span class="p">{</span>
<span class="s1">&#39;max_depth&#39;</span><span class="p">:[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">],</span>
<span class="s1">&#39;min_child_weight&#39;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">gsearch2</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
                <span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span>
                <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test2</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">gsearch2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span><span class="n">train</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;max_depth&#39;: 50, &#39;min_child_weight&#39;: 5}, 0.4190558425538005)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;max_depth&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">50</span>
</pre></div>
</div>
</div>
</div>
<p>Nous pouvons essayer d’affiner l’ajustement.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_test2b</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:[</span><span class="mi">45</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">55</span><span class="p">],</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;max_depth&#39;: 50}, 0.4190558425538005)
</pre></div>
</div>
</div>
</div>
<p>On conserve donc max_depth = 50.</p>
</div>
<div class="section" id="etape-3-gamma">
<h3>Étape 3 : Gamma<a class="headerlink" href="#etape-3-gamma" title="Permalink to this headline">¶</a></h3>
<p>Maintenant, nous répétons le même mécanisme pour le paramètre <em>Gamma</em>.</p>
<ol class="simple">
<li><p>Définir les valeurs de Gamma à tester</p></li>
<li><p>Utiliser GridSearchCV</p></li>
<li><p>Choisir de conserver, modifier, ou d’affiner encore Gamma.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_test3</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;gamma&#39;</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-output tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gsearch3</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">),</span> 
                        <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">gsearch3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span><span class="n">train</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;gamma&#39;: 0.0}, 0.41722053132398057)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<p>Nous ne modifions pas <em>Gamma</em> et laissons le paramètre à 0.</p>
<p>Avant de continuer, nous ré-augmentons n_estimators pour voir où est le modèle si nous augmentons le nombre de boosting rounds.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">xgb2</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
<span class="n">xgb2</span> <span class="o">=</span> <span class="n">xgb2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result_model</span><span class="p">(</span><span class="n">xgb2</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">mat</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Le f1 score vaut 0.42545160420598543
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="etape-4-subsample-et-colsample-bytree">
<h3>Etape 4 : subsample et colsample_bytree<a class="headerlink" href="#etape-4-subsample-et-colsample-bytree" title="Permalink to this headline">¶</a></h3>
<p>Nous rétablissons <em>n_estimators</em> pour la puissance de calcul.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">140</span>
</pre></div>
</div>
</div>
</div>
<p>Génération des paramètres à tester :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_test4</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;subsample&#39;</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">)],</span>
 <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;colsample_bytree&#39;: 0.9, &#39;subsample&#39;: 0.7}, 0.42095524066535334)
</pre></div>
</div>
</div>
</div>
<p>Nous modifions les paramètres identifiés</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;subsample&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">params</span><span class="p">[</span><span class="s2">&quot;colsample_bytree&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span>
</pre></div>
</div>
</div>
</div>
<p>Nous affinons les tests sur ces paramètres.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_test5</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;subsample&#39;</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">100.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">65</span><span class="p">,</span><span class="mi">80</span><span class="p">,</span><span class="mi">5</span><span class="p">)],</span>
 <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">100.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">85</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;colsample_bytree&#39;: 0.9, &#39;subsample&#39;: 0.7}, 0.42095524066535334)
</pre></div>
</div>
</div>
</div>
<p>Cela confirme les valeurs 0.9 et 0.7 trouvées précédemment.</p>
</div>
<div class="section" id="etape-5-reg-alpha">
<h3>Étape 5 : reg_alpha<a class="headerlink" href="#etape-5-reg-alpha" title="Permalink to this headline">¶</a></h3>
<p>Prochaine étape : optimisation de <em>reg_alpha</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_test6</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:[</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;reg_alpha&#39;: 1e-05}, 0.41076480565646045)
</pre></div>
</div>
</div>
</div>
<p>On modifie le paramètre.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;reg_alpha&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-5</span>
</pre></div>
</div>
</div>
</div>
<p>Avant de continuer, nous ré-augmentons n_estimators pour voir où est le modèle si nous augmentons le nombre de boosting rounds.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">xgb3</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
<span class="n">xgb3</span> <span class="o">=</span> <span class="n">xgb3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Le f1 score vaut 0.42837874291880224
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="etape-6-learning-rate">
<h3>Etape 6 : Learning rate<a class="headerlink" href="#etape-6-learning-rate" title="Permalink to this headline">¶</a></h3>
<p>Enfin, nous essayons de diminuer le <em>learning_rate</em> et d’augmenter grandement les <em>n_estimators</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.01</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgb4</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
<span class="n">xgb4</span> <span class="o">=</span> <span class="n">xgb4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Le f1 score vaut 0.4172222222222222
</pre></div>
</div>
</div>
</div>
<p>Le F1-Score ne s’améliore pas, nous revenons aux anciens paramètres.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.1</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="random-under-sampler">
<h2>Random Under Sampler<a class="headerlink" href="#random-under-sampler" title="Permalink to this headline">¶</a></h2>
<p>Une autre idée pour améliorer notre XGBoost est de travailler sur la forme des données d’entrainement. Actuellement le jeux de données est non balancé, c’est-à-dire que nous avons plus de Y ayant une valeur de 0 que de 1.</p>
<p>Pour résoudre ce problème nous utilisons un librairie permettan de réaliser du <strong>random under sampler</strong> et réajustant à souhait la répartition des 1 et des 0 dans notre base de données d’entrainement.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">RandomUnderSampler</span>
</pre></div>
</div>
</div>
</div>
<p>Dans un premier temps nous définissons la fonction <em>model_rus(alpha, model, X_train, Y_train)</em> et <em>f1_scorer(model, X, Y)</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model_rus</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span> <span class="p">:</span>
    <span class="n">rus</span> <span class="o">=</span> <span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">sampling_strategy</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">)</span>
    <span class="n">X_rus</span> <span class="p">,</span> <span class="n">Y_rus</span> <span class="o">=</span> <span class="n">rus</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span> <span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_rus</span><span class="p">,</span><span class="n">Y_rus</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">f1_scorer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span> <span class="p">:</span>
    <span class="n">Y_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">Y_model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">score</span>
</pre></div>
</div>
</div>
</div>
<p>Grâce à ses fonctions, nous évaluons notre modèle XGBoost avec des jeux de données plus ou moins équilibrés.</p>
<div class="math notranslate nohighlight">
\[
\alpha = \frac{\text{Nombre de 1}}{\text{Nombre de 0}}
\]</div>
<p>Lorsque <span class="math notranslate nohighlight">\(\alpha = 1\)</span> les données sont parfaitement balancées (50% /50%).</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">list_model</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">list_alpha</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">score_alpha</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">xgb_rus</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>

<span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="n">list_alpha</span> <span class="p">:</span>
    <span class="n">temp_m</span> <span class="o">=</span> <span class="n">model_rus</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">xgb_rus</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
    <span class="n">list_model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp_m</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_scorer</span><span class="p">(</span><span class="n">temp_m</span><span class="p">,</span><span class="n">X_test</span> <span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
    <span class="n">score_alpha</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">list_alpha</span><span class="p">,</span> <span class="n">score_alpha</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Évolution du F1-Score en fonction de alpha (jeu de données plus ou moins balancé)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/47_xgboost_110_0.png" src="../../_images/47_xgboost_110_0.png" />
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>On choisit donc alpha =  0.833
</pre></div>
</div>
</div>
</div>
<p>Le F1-Score s’améliore grandement lorsque l’entrainement se fait sur des données balancées. Nous nous rappronchons des valeurs du random forest.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Modèle final</span>
<span class="n">xgb5</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
<span class="n">rus</span> <span class="o">=</span> <span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">sampling_strategy</span> <span class="o">=</span> <span class="n">list_alpha</span><span class="p">[</span><span class="n">max_index</span><span class="p">])</span>
<span class="n">X_rus</span> <span class="p">,</span> <span class="n">Y_rus</span> <span class="o">=</span> <span class="n">rus</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span> <span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>
<span class="n">xgb5</span> <span class="o">=</span> <span class="n">xgb5</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_rus</span><span class="p">,</span> <span class="n">Y_rus</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Le f1 score vaut 0.5462996067214873
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/47_xgboost_115_0.png" src="../../_images/47_xgboost_115_0.png" />
</div>
</div>
</div>
<div class="section" id="parametres-finaux">
<h2>Paramètres finaux<a class="headerlink" href="#parametres-finaux" title="Permalink to this headline">¶</a></h2>
<p>Au final, l’optimisation se fait à travers les paramètres et la base de données d’entrainement. La base de données d’entrainement doit être équilibrée avec un coefficient <span class="math notranslate nohighlight">\(\alpha = 0.833\)</span> et les paramètres sont :</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;objective&#39;: &#39;binary:logistic&#39;,
 &#39;base_score&#39;: 0.5,
 &#39;booster&#39;: &#39;gbtree&#39;,
 &#39;colsample_bylevel&#39;: 1,
 &#39;colsample_bynode&#39;: 1,
 &#39;colsample_bytree&#39;: 0.9,
 &#39;gamma&#39;: 0,
 &#39;gpu_id&#39;: -1,
 &#39;interaction_constraints&#39;: &#39;&#39;,
 &#39;learning_rate&#39;: 0.1,
 &#39;max_delta_step&#39;: 0,
 &#39;max_depth&#39;: 50,
 &#39;min_child_weight&#39;: 5,
 &#39;monotone_constraints&#39;: &#39;()&#39;,
 &#39;n_jobs&#39;: 8,
 &#39;num_parallel_tree&#39;: 1,
 &#39;predictor&#39;: &#39;auto&#39;,
 &#39;random_state&#39;: 0,
 &#39;reg_alpha&#39;: 1e-05,
 &#39;reg_lambda&#39;: 1,
 &#39;scale_pos_weight&#39;: 1,
 &#39;subsample&#39;: 0.7,
 &#39;tree_method&#39;: &#39;exact&#39;,
 &#39;validate_parameters&#39;: 1,
 &#39;verbosity&#39;: None,
 &#39;seed&#39;: 27,
 &#39;nthread&#39;: 7,
 &#39;use_label_encoder&#39;: False,
 &#39;n_estimators&#39;: 1000}
</pre></div>
</div>
</div>
</div>
<p>Nous reprendons ces paramètres dans le prochains notebook concernant le modèle final utilisé pour générer les prédictions sur la base test.</p>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>Tuner un modèle XGBoost nécessite énormement de temps de calcul. Dans ce projet, nous avons restreint le nombre de paramètres. Bien sûr, avec davantage de puissance, nous aurions pu calibrer plus précisement les paramètres étudiés et tuner d’autres paramètres non traités dans ce notebook.</p>
<p><br><br><br><br><br></p>
</div>
<div class="section" id="rappels-theoriques">
<h2>Rappels théoriques<a class="headerlink" href="#rappels-theoriques" title="Permalink to this headline">¶</a></h2>
<p>Le Boosting de Gradient est un algorithme d’apprentissage supervisé dont le principe est de combiner les résultats d’un ensemble de modèles moins performants afin de fournir la meilleure prédiction possible.</p>
<p>Un exemple classique est le modèle linéaire défini comme ci-suit  <span class="math notranslate nohighlight">\(\hat{y}_i = \sum_j \theta_j x_{ij}\)</span> qui représente une combinaison de plusieurs variables plus ou moins significatives.</p>
<p>En choisissant judicieusement notre <span class="math notranslate nohighlight">\(y_i\)</span>, nous pouvons à partir de notre jeu de données faire des régressions et de la classification.</p>
<p>Lorque nous entrainons notre modèle, nous cherchons à définir le meilleur paramètre <span class="math notranslate nohighlight">\( \theta  \)</span> qui ajustera nos données <span class="math notranslate nohighlight">\(x_i\)</span> et nous permettra d’obtenir les meilleurs prédictions de <span class="math notranslate nohighlight">\(y_i\)</span>. Pour entrainer notre modèle, nous avons besoin d’une fonction dite d’objectif afin d’estimer si notre modèle est performant ou non. <br />
Notre fonction dite d’objectif est définie de la manière suivante :
$<span class="math notranslate nohighlight">\(\text{obj}(\theta) = L(\theta) + \Omega(\theta)\)</span>$</p>
<p>Dans cette expression nous retrouvons deux composants :<br />
Le premier <span class="math notranslate nohighlight">\(L\)</span>, la fonction d’entrainement, le second <span class="math notranslate nohighlight">\(\Omega\)</span> qui est le terme de régulation.<br />
<span class="math notranslate nohighlight">\(L\)</span> va donc estimer la performance prédicitive de notre modèle.<br />
Un choix classique pour <span class="math notranslate nohighlight">\(L\)</span> est la mesure la mean squared error (MSE) donnée par : $<span class="math notranslate nohighlight">\( L(\theta) = \sum_i (y_i-\hat{y}_i)^2  \)</span>$</p>
<p>Il existe également la fonction de logistic loss qui peut également être utilisée comme fonction d’entrainement:</p>
<div class="math notranslate nohighlight">
\[ L(\theta) = \sum_i[ y_i\ln (1+e^{-\hat{y}_i}) + (1-y_i)\ln (1+e^{\hat{y}_i})]  \]</div>
<p>Le terme de régulation est assez souvent oublié; c’est pourtant lui qui contrôle la compléxité du modèle et nous empêche d’entrainer notre modèle en overfittant.</p>
<p><img alt="Texte alternatif" src="https://drive.google.com/uc?id=1ks-oizjnu3-rThY-gecix6BpKFWy__FM" /></p>
<p>La présentation de la méthode XGBoost ne peut se faire sans introduire la notion d’arbre de décision.</p>
<p><img alt="Texte alternatif" src="https://drive.google.com/uc?id=1R7HcQg2z2cJ14GSCOL45VsWfHGT0-f37" /></p>
<p>Dans notre exemple, il s’agit d’un modèle qui doit classifier suivant deux variables l’âge ainsi que l’utilisation quotidienne d’un ordinateur. Le modèle alloue a chaque échantillon un score de prédiction.</p>
<p>Mathématiquement, le score peut s’écrire sous la forme :</p>
<div class="math notranslate nohighlight">
\[\hat{y}_i = \sum_{k=1}^K f_k(x_i), f_k \in \mathcal{F}\]</div>
<p>où <span class="math notranslate nohighlight">\(K\)</span> est le nombre d’arbres, <span class="math notranslate nohighlight">\(f\)</span> une fonction dans <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> et <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> est l’ensemble des arbres de classification et de regression.<br />
L’objectif est d’optimiser la fonction suivante :</p>
<div class="math notranslate nohighlight">
\[ \text{obj}(\theta) = \sum_i^n l(y_i, \hat{y}_i) + \sum_{k=1}^K \Omega(f_k)\]</div>
<p>Mainteant que nous avons introduit le modèle, nous pouvons passer à l’entrainement de ce dernier. Nous allons définir une fonction d’objectif que nous optimiserons.<br />
Notre fonction d’objectif est défini comme étant :</p>
<div class="math notranslate nohighlight">
\[ \text{obj} = \sum_{i=1}^n l(y_i, \hat{y}_i^{(t)}) + \sum_{i=1}^t\Omega(f_i) \]</div>
<p>Nous devons chercher premièrement les paramètres de notre arbre. Les structures de nos arbres sont contenus dans les fonctions <span class="math notranslate nohighlight">\(f_i\)</span>. Il s’avère complexe d’optimiser la structure d’un arbre, il ne s’agit pas simplement de problèmes de gradients.<br />
Ici nous fixons ce que nous avons à apprendre puis nous ajoutons un arbre à la fois. Notre valeur de prédiction avec un pas de <span class="math notranslate nohighlight">\(t\)</span> pour la fonction <span class="math notranslate nohighlight">\(\hat{y}_i^{(t)}\)</span> s’écrit :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}\\\begin{split}\hat{y}_i^{(0)} &amp;= 0\\
\hat{y}_i^{(1)} &amp;= f_1(x_i) = \hat{y}_i^{(0)} + f_1(x_i)\\
\hat{y}_i^{(2)} &amp;= f_1(x_i) + f_2(x_i)= \hat{y}_i^{(1)} + f_2(x_i)\\
&amp;\dots\\
\hat{y}_i^{(t)} &amp;= \sum_{k=1}^t f_k(x_i)= \hat{y}_i^{(t-1)} + f_t(x_i)\end{split}\\\end{split}\end{aligned}\end{align} \]</div>
<p>La question qui se pose alors est : quel arbre ajouté après un pas ?. La réponse est l’arbre qui optimise le mieux notre prédiction.</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}\\\begin{split}\text{obj}^{(t)} &amp; = \sum_{i=1}^n l(y_i, \hat{y}_i^{(t)}) + \sum_{i=1}^t\Omega(f_i) \\
          &amp; = \sum_{i=1}^n l(y_i, \hat{y}_i^{(t-1)} + f_t(x_i)) + \Omega(f_t) + \mathrm{constant}\end{split}\\\end{split}\end{aligned}\end{align} \]</div>
<p>Lorsque la mean squared error (MSE) est utilisée, notre fonction d’objectif devient</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}\\\begin{split}\text{obj}^{(t)} &amp; = \sum_{i=1}^n (y_i - (\hat{y}_i^{(t-1)} + f_t(x_i)))^2 + \sum_{i=1}^t\Omega(f_i) \\
          &amp; = \sum_{i=1}^n [2(\hat{y}_i^{(t-1)} - y_i)f_t(x_i) + f_t(x_i)^2] + \Omega(f_t) + \mathrm{constant}\end{split}\\\end{split}\end{aligned}\end{align} \]</div>
<p>L’utilisation de la MSE est assez courante avec un résidu et un terme quadratique.
La fonction d’objectif devient alors :</p>
<div class="math notranslate nohighlight">
\[ \text{obj}^{(t)} = \sum_{i=1}^n [l(y_i, \hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t) + \mathrm{constant} \]</div>
<p>où <span class="math notranslate nohighlight">\(g_i\)</span> et <span class="math notranslate nohighlight">\(h_i\)</span> sont :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned} \begin{split}\\\begin{split} g_i &amp;= \partial_{\hat{y}_i^{(t-1)}} l(y_i, \hat{y}_i^{(t-1)})\\
h_i &amp;= \partial_{\hat{y}_i^{(t-1)}}^2 l(y_i, \hat{y}_i^{(t-1)})\end{split}\\\end{split}\end{aligned}\end{align} \]</div>
<p>Après supression de toutes les constantes, nous obtenons :</p>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^n [g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t)\]</div>
<p>Cette expression devient notre objectif pour les nouveaux arbres. La valeur de notre prédiction ne va alors dépendre que de <span class="math notranslate nohighlight">\(g_i\)</span> et <span class="math notranslate nohighlight">\(h_i\)</span>. Il est possible d’optimiser chaque loss function en utilisant simplement les mêmes entrées <span class="math notranslate nohighlight">\(g_i\)</span>et <span class="math notranslate nohighlight">\(h_i\)</span>.</p>
<p>Maintenant que le terme d’entrainement est déterminé, il est nécessaire de définir le terme de régulation qui intervient dans la gestion de la complexité du modèle.<br />
La complexité de notre arbre est représentée par <span class="math notranslate nohighlight">\(\Omega(f)\)</span> qui est defini par la fonction <span class="math notranslate nohighlight">\(f(x)\)</span> :</p>
<div class="math notranslate nohighlight">
\[f_t(x) = w_{q(x)}, w \in R^T, q:R^d\rightarrow \{1,2,\cdots,T\} .\]</div>
<p>où <span class="math notranslate nohighlight">\(w\)</span> est le  vecteur de score, <span class="math notranslate nohighlight">\(q\)</span> est la fonction qui alloue la bonne feuille et <span class="math notranslate nohighlight">\(T\)</span> le nombre de feuilles.
Pour la methode XGBoost, nous pouvons définir la complexité du modèle comme étant :</p>
<div class="math notranslate nohighlight">
\[ \Omega(f) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^T w_j^2 \]</div>
<p>Il existe d’autres façons de définir la complexité du modèle; cependant celle énoncée précédemment s’avère être fonctionnelle et efficace. L’aspect de régulation est souvent sous-estimé voir même ingoré. En définissant la complexité de façon formelle, nous avons un meilleur aperçu de notre modèle et de son niveau de performance.</p>
<p>Structure du score :</p>
<p>Mainteant que nous avons défini notre modèle, notre valeur objectif peut s’écrire de la façon suivante :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}\\\begin{split}\text{obj}^{(t)} &amp;\approx \sum_{i=1}^n [g_i w_{q(x_i)} + \frac{1}{2} h_i w_{q(x_i)}^2] + \gamma T + \frac{1}{2}\lambda \sum_{j=1}^T w_j^2\\
&amp;= \sum^T_{j=1} [(\sum_{i\in I_j} g_i) w_j + \frac{1}{2} (\sum_{i\in I_j} h_i + \lambda) w_j^2 ] + \gamma T\end{split}\\\end{split}\end{aligned}\end{align} \]</div>
<p>où <span class="math notranslate nohighlight">\(I_j = \{i|q(x_i)=j\}\)</span>représentent les indices des nos points dans notre arbre.<br />
L’expression de notre valeur objectif peut être simplifiée.
Nous définissons <span class="math notranslate nohighlight">\(G_j = \sum_{i\in I_j} g_i\)</span> et <span class="math notranslate nohighlight">\(H_j = \sum_{i\in I_j} h_i\)</span>; l’expression de notre valeur objectif devient alors :</p>
<div class="math notranslate nohighlight">
\[\text{obj}^{(t)} = \sum^T_{j=1} [G_jw_j + \frac{1}{2} (H_j+\lambda) w_j^2] +\gamma T\]</div>
<p>où les <span class="math notranslate nohighlight">\(w_j\)</span> sont indépendants, <span class="math notranslate nohighlight">\(G_jw_j+\frac{1}{2}(H_j+\lambda)w_j^2\)</span> est une expression de la forme quadratique. Pour le meilleur <span class="math notranslate nohighlight">\(w_j\)</span> possible, nous pouvons ecrire :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}\\\begin{split}w_j^\ast &amp;= -\frac{G_j}{H_j+\lambda}\\
\text{obj}^\ast &amp;= -\frac{1}{2} \sum_{j=1}^T \frac{G_j^2}{H_j+\lambda} + \gamma T\end{split}\\\end{split}\end{aligned}\end{align} \]</div>
<p>C’est la dernière expression qui va déterminer la qualité de notre modèle en évaluant la qualité de la prédiction.</p>
<p>Après avoir mesuré la qualité de notre modèle, nous allons énumerer le nombre d’arbres possibles afin de choisir le meilleur. C’est probablement impossible à réaliser avec l’infinité de combinaisons possibles. Il faut donc chercher à optimiser l’arbre niveau par niveau. Nous calculons de ce fait le gain entre un arbre et l’autre à l’aide de la formule suivante :</p>
<div class="math notranslate nohighlight">
\[ Gain = \frac{1}{2} \left[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}\right] - \gamma \]</div>
<p>Ici, nous comparons le gain entre deux nouveaux arbres et celui que nous utilisons actuellement. Si le gain est inferieur au <span class="math notranslate nohighlight">\(\gamma\)</span> il est plus préférable de ne pas ajouter le nouvel arbre.</p>
<p><br><br><br><br></p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs\4_modeles"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="46_grad_boost.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Gradient Boosting</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../5_retenu/50_mod_final.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Modèle finale</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By BÉRU Théodore, CHEBAK Soraya, CLAVIER Mathieu, GUICHARD Victor<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>