{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-sXD2QPKVlB"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principe générale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9yig8mEKfwD"
   },
   "source": [
    "Le Boosting de Gradient est un algorithme d’apprentissage supervisé dont le principe est de combiner les résultats d’un ensemble de modèles moins performants afin de fournir la meilleure prédiction possible.\n",
    "\n",
    "Un exemple classique est le modèle linéaire défini comme ci-suit  $\\hat{y}_i = \\sum_j \\theta_j x_{ij}$ qui représente une combinaison de plusieurs variables plus ou moins significatives.\n",
    "\n",
    "En choisissant judicieusement notre $y_i$, nous pouvons à partir de notre jeu de données faire des régressions et de la classification.\n",
    "\n",
    "Lorque nous entrainons notre modèle, nous cherchons à définir le meilleur paramètre $ \\theta  $ qui ajustera nos données $x_i$ et nous permettra d'obtenir les meilleurs prédictions de $y_i$. Pour entrainer notre modèle, nous avons besoin d'une fonction dite d'objectif afin d'estimer si notre modèle est performant ou non. \\\n",
    "Notre fonction dite d'objectif est définie de la manière suivante :\n",
    "$$\\text{obj}(\\theta) = L(\\theta) + \\Omega(\\theta)$$\n",
    "\n",
    "Dans cette expression nous retrouvons deux composants :\\\n",
    "Le premier $L$, la fonction d'entrainement, le second $\\Omega$ qui est le terme de régulation.\\\n",
    "$L$ va donc estimer la performance prédicitive de notre modèle.\\\n",
    "Un choix classique pour $L$ est la mesure la mean squared error (MSE) donnée par : $$ L(\\theta) = \\sum_i (y_i-\\hat{y}_i)^2  $$\n",
    "\n",
    "Il existe également la fonction de logistic loss qui peut également être utilisée comme fonction d'entrainement: \n",
    "\n",
    "$$ L(\\theta) = \\sum_i[ y_i\\ln (1+e^{-\\hat{y}_i}) + (1-y_i)\\ln (1+e^{\\hat{y}_i})]  $$\n",
    "\n",
    "Le terme de régulation est assez souvent oublié; c'est pourtant lui qui contrôle la compléxité du modèle et nous empêche d'entrainer notre modèle en overfittant.\n",
    "\n",
    "![Texte alternatif](https://drive.google.com/uc?id=1ks-oizjnu3-rThY-gecix6BpKFWy__FM)\n",
    "\n",
    "La présentation de la méthode XGBoost ne peut se faire sans introduire la notion d'arbre de décision.\n",
    "\n",
    "![Texte alternatif](https://drive.google.com/uc?id=1R7HcQg2z2cJ14GSCOL45VsWfHGT0-f37)\n",
    "\n",
    "Dans notre exemple, il s'agit d'un modèle qui doit classifier suivant deux variables l'âge ainsi que l'utilisation quotidienne d'un ordinateur. Le modèle alloue a chaque échantillon un score de prédiction.\n",
    "\n",
    "Mathématiquement, le score peut s'écrire sous la forme :\n",
    "\n",
    "$$\\hat{y}_i = \\sum_{k=1}^K f_k(x_i), f_k \\in \\mathcal{F}$$\n",
    "\n",
    "où $K$ est le nombre d'arbres, $f$ une fonction dans $\\mathcal{F}$ et $\\mathcal{F}$ est l'ensemble des arbres de classification et de regression.\\\n",
    "L'objectif est d'optimiser la fonction suivante : \n",
    "\n",
    "$$ \\text{obj}(\\theta) = \\sum_i^n l(y_i, \\hat{y}_i) + \\sum_{k=1}^K \\Omega(f_k)$$\n",
    "\n",
    "Mainteant que nous avons introduit le modèle, nous pouvons passer à l'entrainement de ce dernier. Nous allons définir une fonction d'objectif que nous optimiserons.\\\n",
    "Notre fonction d'objectif est défini comme étant :\n",
    "\n",
    "$$ \\text{obj} = \\sum_{i=1}^n l(y_i, \\hat{y}_i^{(t)}) + \\sum_{i=1}^t\\Omega(f_i) $$\n",
    "\n",
    "Nous devons chercher premièrement les paramètres de notre arbre. Les structures de nos arbres sont contenus dans les fonctions $f_i$. Il s'avère complexe d'optimiser la structure d'un arbre, il ne s'agit pas simplement de problèmes de gradients.\\\n",
    "Ici nous fixons ce que nous avons à apprendre puis nous ajoutons un arbre à la fois. Notre valeur de prédiction avec un pas de $t$ pour la fonction $\\hat{y}_i^{(t)}$ s'écrit : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{split}\n",
    "\\hat{y}_i^{(0)} &= 0\\\\\n",
    "\\hat{y}_i^{(1)} &= f_1(x_i) = \\hat{y}_i^{(0)} + f_1(x_i)\\\\\n",
    "\\hat{y}_i^{(2)} &= f_1(x_i) + f_2(x_i)= \\hat{y}_i^{(1)} + f_2(x_i)\\\\\n",
    "&\\dots\\\\\n",
    "\\hat{y}_i^{(t)} &= \\sum_{k=1}^t f_k(x_i)= \\hat{y}_i^{(t-1)} + f_t(x_i)\n",
    "\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La question qui se pose alors est : quel arbre ajouté après un pas ?. La réponse est l'arbre qui optimise le mieux notre prédiction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{split}\n",
    "\\text{obj}^{(t)} & = \\sum_{i=1}^n l(y_i, \\hat{y}_i^{(t)}) + \\sum_{i=1}^t\\Omega(f_i) \\\\\n",
    "          & = \\sum_{i=1}^n l(y_i, \\hat{y}_i^{(t-1)} + f_t(x_i)) + \\Omega(f_t) + \\mathrm{constant}\n",
    "\\end{split}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1QCDxpK3NYm"
   },
   "source": [
    "Lorsque la mean squared error (MSE) est utilisée, notre fonction d'objectif devient \n",
    "\n",
    "\\begin{split}\n",
    "\\text{obj}^{(t)} & = \\sum_{i=1}^n (y_i - (\\hat{y}_i^{(t-1)} + f_t(x_i)))^2 + \\sum_{i=1}^t\\Omega(f_i) \\\\\n",
    "          & = \\sum_{i=1}^n [2(\\hat{y}_i^{(t-1)} - y_i)f_t(x_i) + f_t(x_i)^2] + \\Omega(f_t) + \\mathrm{constant}\n",
    "\\end{split}\n",
    "\n",
    "L'utilisation de la MSE est assez courante avec un résidu et un terme quadratique.\n",
    "La fonction d'objectif devient alors : \n",
    "\n",
    "$$ \\text{obj}^{(t)} = \\sum_{i=1}^n [l(y_i, \\hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \\frac{1}{2} h_i f_t^2(x_i)] + \\Omega(f_t) + \\mathrm{constant} $$\n",
    " \n",
    " où $g_i$ et $h_i$ sont :\n",
    "\n",
    " \\begin{split}\n",
    " g_i &= \\partial_{\\hat{y}_i^{(t-1)}} l(y_i, \\hat{y}_i^{(t-1)})\\\\\n",
    "h_i &= \\partial_{\\hat{y}_i^{(t-1)}}^2 l(y_i, \\hat{y}_i^{(t-1)})\n",
    "\\end{split}\n",
    "\n",
    "Après supression de toutes les constantes, nous obtenons : \n",
    "\n",
    "$$\\sum_{i=1}^n [g_i f_t(x_i) + \\frac{1}{2} h_i f_t^2(x_i)] + \\Omega(f_t)$$\n",
    "\n",
    "Cette expression devient notre objectif pour les nouveaux arbres. La valeur de notre prédiction ne va alors dépendre que de $g_i$ et $h_i$. Il est possible d'optimiser chaque loss function en utilisant simplement les mêmes entrées $g_i$et $h_i$.\n",
    "\n",
    "Maintenant que le terme d'entrainement est déterminé, il est nécessaire de définir le terme de régulation qui intervient dans la gestion de la complexité du modèle.\\\n",
    "La complexité de notre arbre est représentée par $\\Omega(f)$ qui est defini par la fonction $f(x)$ :\n",
    "\n",
    "$$f_t(x) = w_{q(x)}, w \\in R^T, q:R^d\\rightarrow \\{1,2,\\cdots,T\\} .$$\n",
    "\n",
    "où $w$ est le  vecteur de score, $q$ est la fonction qui alloue la bonne feuille et $T$ le nombre de feuilles.\n",
    "Pour la methode XGBoost, nous pouvons définir la complexité du modèle comme étant :\n",
    "\n",
    "$$ \\Omega(f) = \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^T w_j^2 $$\n",
    "\n",
    "Il existe d'autres façons de définir la complexité du modèle; cependant celle énoncée précédemment s'avère être fonctionnelle et efficace. L'aspect de régulation est souvent sous-estimé voir même ingoré. En définissant la complexité de façon formelle, nous avons un meilleur aperçu de notre modèle et de son niveau de performance.\n",
    "\n",
    "Structure du score :\n",
    "\n",
    "Mainteant que nous avons défini notre modèle, notre valeur objectif peut s'écrire de la façon suivante :\n",
    "\n",
    "\\begin{split}\n",
    "\\text{obj}^{(t)} &\\approx \\sum_{i=1}^n [g_i w_{q(x_i)} + \\frac{1}{2} h_i w_{q(x_i)}^2] + \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^T w_j^2\\\\\n",
    "&= \\sum^T_{j=1} [(\\sum_{i\\in I_j} g_i) w_j + \\frac{1}{2} (\\sum_{i\\in I_j} h_i + \\lambda) w_j^2 ] + \\gamma T\n",
    "\\end{split}\n",
    "\n",
    "où $I_j = \\{i|q(x_i)=j\\}$représentent les indices des nos points dans notre arbre.\\\n",
    "L'expression de notre valeur objectif peut être simplifiée.\n",
    "Nous définissons $G_j = \\sum_{i\\in I_j} g_i$ et $H_j = \\sum_{i\\in I_j} h_i$; l'expression de notre valeur objectif devient alors :\n",
    "\n",
    "$$\\text{obj}^{(t)} = \\sum^T_{j=1} [G_jw_j + \\frac{1}{2} (H_j+\\lambda) w_j^2] +\\gamma T$$\n",
    "\n",
    "où les $w_j$ sont indépendants, $G_jw_j+\\frac{1}{2}(H_j+\\lambda)w_j^2$ est une expression de la forme quadratique. Pour le meilleur $w_j$ possible, nous pouvons ecrire : \n",
    "\n",
    "\\begin{split}\n",
    "w_j^\\ast &= -\\frac{G_j}{H_j+\\lambda}\\\\\n",
    "\\text{obj}^\\ast &= -\\frac{1}{2} \\sum_{j=1}^T \\frac{G_j^2}{H_j+\\lambda} + \\gamma T\n",
    "\\end{split}\n",
    "\n",
    "C'est la dernière expression qui va déterminer la qualité de notre modèle en évaluant la qualité de la prédiction.\n",
    "\n",
    "Après avoir mesuré la qualité de notre modèle, nous allons énumerer le nombre d'arbres possibles afin de choisir le meilleur. C'est probablement impossible à réaliser avec l'infinité de combinaisons possibles. Il faut donc chercher à optimiser l'arbre niveau par niveau. Nous calculons de ce fait le gain entre un arbre et l'autre à l'aide de la formule suivante : \n",
    "\n",
    "$$ Gain = \\frac{1}{2} \\left[\\frac{G_L^2}{H_L+\\lambda}+\\frac{G_R^2}{H_R+\\lambda}-\\frac{(G_L+G_R)^2}{H_L+H_R+\\lambda}\\right] - \\gamma $$\n",
    "\n",
    "Ici, nous comparons le gain entre deux nouveaux arbres et celui que nous utilisons actuellement. Si le gain est inferieur au $\\gamma$ il est plus préférable de ne pas ajouter le nouvel arbre.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "XgBoost.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}